# Real-Time Emotion Detection with CNN Hardware Acceleration

This project implements a real-time emotion detection system that uses both a deep learning-based software model and a Verilator-simulated hardware accelerator for CNN inference. It provides a hands-on demonstration of hybrid AI acceleration using Python, OpenCV, Keras, and SystemVerilog.

---

## Overview

The core objective of this project is to:

* Detect facial emotions in real-time using webcam input.
* Perform inference using two modes:

  * **Software-based**: Uses a pre-trained Keras CNN model.
  * **Hardware-accelerated**: Uses a SystemVerilog CNN implemented and simulated using Verilator.
* Log and compare inference accuracy and execution time.

---

## File & Directory Structure

#### `emotion_detector_with_model.py`

Main script that captures video from the webcam, detects faces, preprocesses the image, and runs inference using either:

* `DeepFace` (software mode)
* `Verilator CNN accelerator` (hardware mode)

Logs results and inference times into CSVs for further analysis.

#### `emotion_model.h5`

Pre-trained Keras CNN model file trained on FER-2013 dataset for emotion classification.

#### `emotionmodel_cnn.py`

Contains the architecture of the CNN model. Used during training (`train_emotion_cnn.py`).

#### `train_emotion_cnn.py`

Python script to train the CNN model using the `fer2013` dataset. It loads the dataset, applies preprocessing, and saves the trained model to `emotion_model.h5`.

#### `emotiondetection.py`

An earlier or alternative version of the emotion detector script. Might have been used during initial development.

#### `fer2013/` and `fer2013.zip`

FER-2013 dataset organized into subfolders for Keras' `flow_from_directory`. Contains training and testing emotion-labeled face images.

#### `frame_input.txt`

Debugging file that stores a single frame's flattened input image (normalized grayscale).

#### `requirements.txt`

Python dependencies for the project. Includes `keras`, `tensorflow`, `opencv-python`, `numpy`, and `deepface`.

---

### Accelerator Platform Used: Verilator

#### `cnn_accelerator.sv`

SystemVerilog description of the CNN-based hardware accelerator. It:

* Accepts 48x48 grayscale pixel inputs
* Computes a prediction (emotion class: 0-6)
* Outputs the result using a ready/valid handshake

#### `sim_main.cpp`

C++ testbench wrapper that drives the Verilated simulation. It:

* Reads preprocessed pixel values from `input_image.txt`
* Feeds them into `cnn_accelerator`
* Captures `emotion_out` when `valid_out` is high
* Prints the predicted class (captured by Python)

#### `input_image.txt`

Text file containing normalized pixel values (flattened from shape `[1,48,48,1]`). Written by the Python script before calling the simulator.

#### `emotion_predictions.csv`

Contains emotion predictions made during the hardware inference mode. Useful for accuracy analysis and debugging.

#### `inference_log.csv`

Central CSV log that contains the inference time and detected emotion for each frame from both software and hardware modes.

#### `analyze_emotion_results.py`

Python script for generating comparative plots (e.g., accuracy distribution, average inference time). Helps analyze performance improvements from hardware acceleration.

#### `verilator_test.py`

A test utility to run and debug Verilator simulation independently from the webcam pipeline.

#### `obj_dir/` and `verilator/`

Generated by Verilator during the compilation of SystemVerilog code.

* `obj_dir/`: Compiled simulation objects and headers
* `verilator/`: Intermediate build files and possibly Makefiles

#### `wrapper.cpp`, `verilator.test`

Support/test files that may serve as older testbenches or experimental wrappers.

---

## How It Works (Pipeline)

### Software Mode (DeepFace)

1. Webcam frame is captured using OpenCV.
2. Frame is converted to grayscale and resized to 48x48.
3. `DeepFace.analyze()` is used to predict emotion.
4. Results are logged with inference time into `inference_log.csv`.

### Hardware Mode (Verilator Simulation)

1. Frame is preprocessed (grayscale, resized, normalized).
2. Pixel data is saved to `input_image.txt`.
3. Python script invokes the Verilator simulation using `subprocess.run()`.
4. `sim_main.cpp` reads pixel data and simulates `cnn_accelerator`.
5. When `valid_out` goes high, it prints the predicted emotion class.
6. Python reads the prediction, maps class index to emotion label.
7. Logs result and timing to `inference_log.csv` and `emotion_predictions.csv`.

---

## Output Logs

* **`inference_log.csv`**

  * Columns: Frame, Emotion\_HW, Time\_HW, Emotion\_SW, Time\_SW
  * Used to compare prediction and performance side-by-side.

* **`emotion_predictions.csv`**

  * Contains only hardware prediction labels.

---

## Key Achievements

* **System-level integration**: Combines software-based deep learning and RTL-level hardware design.
* **Real-time inference**: Uses live webcam feed for demonstration.
* **Performance measurement**: Compares inference speed between CPU and hardware accelerator.
* **Portable design**: Verilator-based design allows validation without FPGA.

---

## Setup & Run Instructions

### 1. Install Dependencies

```bash
pip install -r requirements.txt
```

### 2. Activate Environment

```bash
source emotion_env/Scripts/activate  # or activate using Git Bash/PowerShell
```

### 3. Run Real-Time Detection

```bash
python emotion_detector_with_model.py
```

### 4. View Logs

Check `inference_log.csv` and `emotion_predictions.csv` in the `accelerator_verilator/` folder.

### 5. (Optional) Analyze Performance

```bash
python analyze_emotion_results.py
```

---

## Future Work

* Deploy hardware design on an FPGA (e.g., using Vitis HLS or Vivado)
* Improve CNN architecture and port more layers to hardware
* Add multi-face detection and track emotions over time
* Use quantized/optimized models (e.g., ONNX + VTA)

---

## Credits

* FER-2013 dataset for emotion classification
* Keras and TensorFlow for training
* Verilator for RTL simulation
* DeepFace for baseline comparison

---

This project demonstrates an end-to-end hybrid AI pipeline combining Python-based machine learning with SystemVerilog simulation, providing insights into performance tradeoffs and acceleration opportunities in embedded AI systems.
