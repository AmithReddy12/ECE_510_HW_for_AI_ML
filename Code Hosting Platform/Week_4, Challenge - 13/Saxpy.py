# -*- coding: utf-8 -*-
"""Untitled0.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1jtWkFBthPTOGtOBAu9mPW5acsgbhiidn
"""

!nvidia-smi
!apt-get update -qq
!apt-get install -y nvidia-cuda-toolkit  > /dev/null
!nvcc --version | head -n 1

!nvcc --version

# Commented out IPython magic to ensure Python compatibility.
# %%bash
# cat > hello.cu <<'EOF'
# #include <stdio.h>
# __global__ void hello(){ printf("Hello from GPU!\\n"); }
# int main(){
#     hello<<<1,1>>>();
#     cudaDeviceSynchronize();
#     return 0;
# }
# EOF
# 
# nvcc hello.cu -o hello
# ./hello

!git clone --depth 1 https://github.com/NVIDIA-developer-blog/code-samples.git

# Commented out IPython magic to ensure Python compatibility.
# %cd code-samples/posts/easy-intro-cuda/saxpy

# Commented out IPython magic to ensure Python compatibility.
!git clone --depth 1 https://github.com/NVIDIA-developer-blog/code-samples.git
# %cd code-samples/posts/easy-intro-cuda/saxpy

!rm -rf code-samples

!git clone --depth 1 https://github.com/NVIDIA-developer-blog/code-samples.git

# Commented out IPython magic to ensure Python compatibility.
# %cd /content/code-samples/posts/easy-intro-cuda/saxpy

!rm -rf code-samples

!git clone --depth 1 https://github.com/NVIDIA-developer-blog/code-samples.git

!find code-samples -type f -name 'saxpy.cu'

# Commented out IPython magic to ensure Python compatibility.
# %cd code-samples/posts/grcuda/kernel

!ls

!nvcc -O3 saxpy.cu -o saxpy

!./saxpy

!ls

# Commented out IPython magic to ensure Python compatibility.
# %%bash
# cat > saxpy_bench.cu <<'EOF'
# #include <cstdio>
# #include <cuda_runtime.h>
# 
# __global__ void saxpy(int n, float a, float *x, float *y){
#     int i = blockIdx.x * blockDim.x + threadIdx.x;
#     if(i < n) y[i] = a * x[i] + y[i];
# }
# 
# int main(){
#     const int first_pow = 15, last_pow = 25;        // 2^15 … 2^25
#     for(int p = first_pow; p <= last_pow; ++p){
#         int N = 1 << p;
#         size_t bytes = N * sizeof(float);
# 
#         float *h_x = (float*)malloc(bytes);
#         float *h_y = (float*)malloc(bytes);
#         for(int i = 0; i < N; ++i){ h_x[i] = 1.0f; h_y[i] = 2.0f; }
# 
#         float *d_x, *d_y;
#         cudaMalloc(&d_x, bytes);  cudaMalloc(&d_y, bytes);
#         cudaMemcpy(d_x, h_x, bytes, cudaMemcpyHostToDevice);
#         cudaMemcpy(d_y, h_y, bytes, cudaMemcpyHostToDevice);
# 
#         dim3 block(256);
#         dim3 grid((N + block.x - 1) / block.x);
# 
#         cudaEvent_t t0, t1;
#         cudaEventCreate(&t0);  cudaEventCreate(&t1);
# 
#         // total time (H2D + kernel + D2H)
#         cudaEventRecord(t0);
#         saxpy<<<grid, block>>>(N, 2.0f, d_x, d_y);
#         cudaMemcpy(h_y, d_y, bytes, cudaMemcpyDeviceToHost);
#         cudaEventRecord(t1);  cudaEventSynchronize(t1);
#         float total_ms;  cudaEventElapsedTime(&total_ms, t0, t1);
# 
#         // kernel‑only time
#         cudaEventRecord(t0);
#         saxpy<<<grid, block>>>(N, 2.0f, d_x, d_y);
#         cudaEventRecord(t1);  cudaEventSynchronize(t1);
#         float kernel_ms; cudaEventElapsedTime(&kernel_ms, t0, t1);
# 
#         printf("%d,%f,%f\n", N, total_ms, kernel_ms);   // CSV line
# 
#         cudaFree(d_x); cudaFree(d_y); free(h_x); free(h_y);
#         cudaEventDestroy(t0); cudaEventDestroy(t1);
#     }
#     return 0;
# }
# EOF

!nvcc -O3 saxpy_bench.cu -o saxpy_bench

!./saxpy_bench > /content/saxpy_times.csv

!head /content/saxpy_times.csv

import numpy as np, matplotlib.pyplot as plt
N, total, kernel = np.loadtxt("/content/saxpy_times.csv", delimiter=",", unpack=True)
plt.bar(np.log2(N)-0.15, total, width=0.3, label="total")
plt.bar(np.log2(N)+0.15, kernel, width=0.3, label="kernel only")
plt.xlabel("log2(problem size)"); plt.ylabel("time (ms)")
plt.title("SAXPY runtime on Colab Tesla T4"); plt.legend(); plt.show()

